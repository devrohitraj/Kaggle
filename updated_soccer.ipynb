{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "30382032-e446-0446-a2b5-fe26833e187d"
   },
   "source": [
    "Importing libraries for further use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "ae6ddcce-8a23-cb94-0181-f73d3723fde5"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b08d92d9-e05c-ec8d-903e-f28b882c3d3e"
   },
   "source": [
    "Getting dataset ready for coming anaysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "a851415e-a5e7-7ad6-b93d-6c3e8fd0c23c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(183978, 42)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data (make sure you have downloaded database.sqlite)\n",
    "with sqlite3.connect('../input/database.sqlite') as con:\n",
    "    Player_Attributes = pd.read_sql_query(\"SELECT * from Player_Attributes\", con)\n",
    "Player_Attributes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b07bb8c5-ab23-4317-2f9b-0b1b679198ba"
   },
   "source": [
    "Selecting relevant data field and removing fields that will not improve our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "c9a5548e-2729-d0ac-82b3-962110809343"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>potential</th>\n",
       "      <th>preferred_foot</th>\n",
       "      <th>attacking_work_rate</th>\n",
       "      <th>defensive_work_rate</th>\n",
       "      <th>crossing</th>\n",
       "      <th>finishing</th>\n",
       "      <th>heading_accuracy</th>\n",
       "      <th>short_passing</th>\n",
       "      <th>volleys</th>\n",
       "      <th>dribbling</th>\n",
       "      <th>...</th>\n",
       "      <th>vision</th>\n",
       "      <th>penalties</th>\n",
       "      <th>marking</th>\n",
       "      <th>standing_tackle</th>\n",
       "      <th>sliding_tackle</th>\n",
       "      <th>gk_diving</th>\n",
       "      <th>gk_handling</th>\n",
       "      <th>gk_kicking</th>\n",
       "      <th>gk_positioning</th>\n",
       "      <th>gk_reflexes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71.0</td>\n",
       "      <td>right</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>49.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>...</td>\n",
       "      <td>54.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71.0</td>\n",
       "      <td>right</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>49.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>...</td>\n",
       "      <td>54.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66.0</td>\n",
       "      <td>right</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>49.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>...</td>\n",
       "      <td>54.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65.0</td>\n",
       "      <td>right</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>48.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>53.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65.0</td>\n",
       "      <td>right</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>48.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>53.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   potential preferred_foot attacking_work_rate defensive_work_rate  crossing  \\\n",
       "0       71.0          right              medium              medium      49.0   \n",
       "1       71.0          right              medium              medium      49.0   \n",
       "2       66.0          right              medium              medium      49.0   \n",
       "3       65.0          right              medium              medium      48.0   \n",
       "4       65.0          right              medium              medium      48.0   \n",
       "\n",
       "   finishing  heading_accuracy  short_passing  volleys  dribbling  \\\n",
       "0       44.0              71.0           61.0     44.0       51.0   \n",
       "1       44.0              71.0           61.0     44.0       51.0   \n",
       "2       44.0              71.0           61.0     44.0       51.0   \n",
       "3       43.0              70.0           60.0     43.0       50.0   \n",
       "4       43.0              70.0           60.0     43.0       50.0   \n",
       "\n",
       "      ...       vision  penalties  marking  standing_tackle  sliding_tackle  \\\n",
       "0     ...         54.0       48.0     65.0             69.0            69.0   \n",
       "1     ...         54.0       48.0     65.0             69.0            69.0   \n",
       "2     ...         54.0       48.0     65.0             66.0            69.0   \n",
       "3     ...         53.0       47.0     62.0             63.0            66.0   \n",
       "4     ...         53.0       47.0     62.0             63.0            66.0   \n",
       "\n",
       "   gk_diving  gk_handling  gk_kicking  gk_positioning  gk_reflexes  \n",
       "0        6.0         11.0        10.0             8.0          8.0  \n",
       "1        6.0         11.0        10.0             8.0          8.0  \n",
       "2        6.0         11.0        10.0             8.0          8.0  \n",
       "3        5.0         10.0         9.0             7.0          7.0  \n",
       "4        5.0         10.0         9.0             7.0          7.0  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#select relevant fields\n",
    "Player_Attributes.dropna(inplace=True)\n",
    "Player_Attributes.drop(['id', 'player_fifa_api_id', 'player_api_id', 'date'], axis = 1, inplace = True)\n",
    "overall_rating = Player_Attributes['overall_rating']\n",
    "features = Player_Attributes.drop('overall_rating', axis = 1)\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d92e68f8-23b0-b9ca-55a5-8f8e9a278732",
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "aa2d85f9-c52d-66ad-ced3-c0d8b0c18c67"
   },
   "source": [
    "Use pandas get_dummies to convert categorical data field into numerical data field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "71a0360f-4aab-cf70-cf57-b019dc735b14"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from sklearn import preprocessing\\n\\nle_sex = preprocessing.LabelEncoder()\\n\\n#to convert into numbers\\n\\nfeatures.preferred_foot = le_sex.fit_transform(features.preferred_foot)\\nfeatures.attacking_work_rate = le_sex.fit_transform(features.attacking_work_rate)\\nfeatures.defensive_work_rate = le_sex.fit_transform(features.defensive_work_rate)\\nfeatures.head()\\n\\n# to convert back\\n# train.Sex = le_sex.inverse_transform(train.Sex)'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use LabelEncoder to convert categorical data field into numerical data field\n",
    "'''from sklearn import preprocessing\n",
    "\n",
    "le_sex = preprocessing.LabelEncoder()\n",
    "\n",
    "#to convert into numbers\n",
    "\n",
    "features.preferred_foot = le_sex.fit_transform(features.preferred_foot)\n",
    "features.attacking_work_rate = le_sex.fit_transform(features.attacking_work_rate)\n",
    "features.defensive_work_rate = le_sex.fit_transform(features.defensive_work_rate)\n",
    "features.head()\n",
    "\n",
    "# to convert back\n",
    "# train.Sex = le_sex.inverse_transform(train.Sex)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "9d052eb0-372f-78e5-eff0-bb9b803d4f95"
   },
   "outputs": [],
   "source": [
    "# Use pandas get_dummies to convert categorical value into numerical\n",
    "features = pd.get_dummies(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a823d43e-11bb-4a26-cacc-74fe639e3c8c"
   },
   "source": [
    "As GK attributes range is lower compare to other players, so we will scale our feature columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "6f967064-07b0-0b49-5f15-8ef511fe34cd"
   },
   "outputs": [],
   "source": [
    "# Feature scaling using MinMaxScaler\n",
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "scaled_features = min_max_scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "56c8b890-b99c-32e3-6751-a552ac15cc03"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"#b Let's use Standard scaler now to scale the data\\nfrom sklearn import preprocessing\\nstd_scaler = preprocessing.StandardScaler()\\nscaled_features = std_scaler.fit_transform(features)\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''#b Let's use Standard scaler now to scale the data\n",
    "from sklearn import preprocessing\n",
    "std_scaler = preprocessing.StandardScaler()\n",
    "scaled_features = std_scaler.fit_transform(features)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8d97d8bc-8911-2eee-d103-c2d493a4b844"
   },
   "source": [
    "Using PCA and SelectKBest of feature_selection to reduce feature data, improve accuracy, and to see who performs well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "90f3ea55-e483-58c5-290a-83ea58a327f4"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 6)\n",
    "pca_features = pca.fit_transform(scaled_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "242cb5a9-8379-0c7d-df6d-d60846c7d917"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Feature selection using sklearn SelectKBest\\nfrom sklearn.feature_selection import SelectKBest\\nfrom sklearn.feature_selection import f_regression\\nfeature_reg = SelectKBest(f_regression, k=6)\\nX_new = feature_reg.fit_transform(scaled_features, overall_rating)'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Feature selection using sklearn SelectKBest\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "feature_reg = SelectKBest(f_regression, k=6)\n",
    "X_new = feature_reg.fit_transform(scaled_features, overall_rating)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d21bbd09-e464-f788-ced6-6997d943d015"
   },
   "source": [
    "**Decision tree is good if accuracy matters(r2 = 0.95) but it takes little longer time to train(~8 sec).\n",
    "But SGD regressor is giving little less accuracy(r2 = 0.84) and it is incredibly fast(~0.8 sec).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "530233fd-d804-aef3-b0d0-d426f25a6211"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Decision Tree\n",
      "--------------------\n",
      "Time taken to train the model: 4.926128149032593\n",
      "Time taken to predict the model: 0.19277596473693848\n",
      "r2 score of this model on testing set is: 0.9492279197619804\n",
      "r2 score of this model on training set is: 0.9988644730721816\n",
      "--------------------\n",
      "SGDRegressor\n",
      "--------------------\n",
      "Time taken to train the model: 0.3004744052886963\n",
      "Time taken to predict the model: 0.02175140380859375\n",
      "r2 score of this model on testing set is: 0.8397390612017024\n",
      "r2 score of this model on training set is: 0.8413065001371176\n"
     ]
    }
   ],
   "source": [
    "# Train and predict model on Decision tree and on SGD regressor\n",
    "from sklearn import tree\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from time import time\n",
    "\n",
    "reg1 = tree.DecisionTreeClassifier()\n",
    "reg2 = linear_model.SGDRegressor()\n",
    "\n",
    "regs = {reg1:\"Decision Tree\", reg2:\"SGDRegressor\"}\n",
    "\n",
    "for key in regs:\n",
    "    t0 = time()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(scaled_features, overall_rating, test_size=0.25, random_state=0)\n",
    "\n",
    "    print (\"--------------------\")\n",
    "    print (regs[key])\n",
    "    print (\"--------------------\")\n",
    "\n",
    "    t1 = time()\n",
    "    key.fit(X_train, y_train)\n",
    "    print (\"Time taken to train the model: {}\".format(time()-t1))\n",
    "\n",
    "    t2 = time()\n",
    "    pred_test = key.predict(X_test)\n",
    "    pred_train = key.predict(X_train)\n",
    "    print (\"Time taken to predict the model: {}\".format(time()-t2))\n",
    "\n",
    "    t3 = time()\n",
    "    print (\"r2 score of this model on testing set is: {}\".format(r2_score(y_test, pred_test)))\n",
    "    print (\"r2 score of this model on training set is: {}\".format(r2_score(y_train, pred_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "04261a88-c14e-5524-cf0c-318b4b29f47c"
   },
   "source": [
    "I have commented the GridSearch algorithm as it was taking a lot time(~ 150 sec) to execute.\n",
    "I will tune parameters manually in each ML algorithm later that is returned by GridSearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "40e74bf0-34a0-4cf6-7479-65f4c8067f1f"
   },
   "outputs": [],
   "source": [
    "# Use GridSearch to tune the model\n",
    "def fit_model(X, y):\n",
    "    \"\"\" Performs grid search over the 'max_depth' parameter for a \n",
    "        decision tree regressor trained on the input data [X, y]. \"\"\"\n",
    "    \n",
    "    # Create cross-validation sets from the training data\n",
    "    from sklearn.cross_validation import ShuffleSplit\n",
    "    cv_sets = ShuffleSplit(X.shape[0], n_iter = 10, test_size = 0.20, random_state = 0)\n",
    "\n",
    "    # TODO: Create a decision tree regressor object\n",
    "    from sklearn.tree import DecisionTreeRegressor\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn import linear_model\n",
    "    \n",
    "    \n",
    "    regressor1 = DecisionTreeRegressor()\n",
    "    regressor2 = SVC()\n",
    "    regressor3 = linear_model.SGDRegressor()\n",
    "\n",
    "    # TODO: Create a dictionary for the parameter 'max_depth' with a range from 1 to 10\n",
    "    tree_params = {'max_depth' : [3, 6, 9, 20, 100], 'min_samples_split':[2, 3, 4, 5]}\n",
    "    svm_params = {'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],'C': [1, 10, 100, 1000]},{'kernel': ['linear'], 'C': [1, 10, 100, 1000]}\n",
    "    sgd_params = {'loss':['squared_loss', 'huber'], 'penalty': ['none', 'l2', 'l1', 'elasticnet'], 'n_iter':[10, 75, 100, 500]}\n",
    "    \n",
    "    \n",
    "    # TODO: Transform 'performance_metric' into a scoring function using 'make_scorer' \n",
    "    from sklearn.metrics import make_scorer\n",
    "    scoring_fnc = make_scorer(performance_metric)\n",
    "\n",
    "    # TODO: Create the grid search object\n",
    "    from sklearn.grid_search import GridSearchCV\n",
    "    \n",
    "    # Updated cv_sets and scoring parameter\n",
    "    grid = GridSearchCV(regressor3, sgd_params, scoring = scoring_fnc, cv = cv_sets)\n",
    "\n",
    "    # Fit the grid search object to the data to compute the optimal model\n",
    "    grid = grid.fit(X, y)\n",
    "\n",
    "    # Return the optimal model after fitting the data\n",
    "    return grid.best_estimator_\n",
    "\n",
    "def performance_metric(y_true, y_predict):\n",
    "    \n",
    "    # TODO: Calculate the performance score between 'y_true' and 'y_predict'\n",
    "    from sklearn.metrics import r2_score\n",
    "    \n",
    "    score = r2_score(y_true, y_predict)\n",
    "    # Return the score\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "edf5abe5-6ab5-57d1-1e6c-59d0e64c94b3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from time import time\\nt0 = time()\\ngrid_reg = fit_model(pca_features, overall_rating)\\nprint (grid_reg.score)\\n# grid_pred = grid_reg()\\nprint (\"Time taken to train and predict using GridSearch: {}\".format(time() - t0))\\nprint (\"Best parameters are: {}\".format(grid_reg.get_params()))'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from time import time\n",
    "t0 = time()\n",
    "grid_reg = fit_model(pca_features, overall_rating)\n",
    "print (grid_reg.score)\n",
    "# grid_pred = grid_reg()\n",
    "print (\"Time taken to train and predict using GridSearch: {}\".format(time() - t0))\n",
    "print (\"Best parameters are: {}\".format(grid_reg.get_params()))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "4a45b3b1-f464-11d4-f886-47d7edce3f6f",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_change_revision": 65,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
